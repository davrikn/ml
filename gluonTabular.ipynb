{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b268a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import ut\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf07bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prediction(location, time_limit):\n",
    "    x_train, x_test = ut.preprocess_category(location)\n",
    "    x_train.drop([\"time\"], axis=1, inplace=True)\n",
    "\n",
    "    x_train['date_forecast'] = pd.to_datetime(x_train['date_forecast'])\n",
    "\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    label = 'pv_measurement'\n",
    "    train_data = TabularDataset(x_train)\n",
    "    \n",
    "    test_data = TabularDataset(x_test)\n",
    "    \n",
    "\n",
    "    predictor = TabularPredictor(label=label,\n",
    "                                 path=\"AutoGluonTesting\",\n",
    "                                 eval_metric='mean_absolute_error')\n",
    "\n",
    "    predictor.fit(train_data,\n",
    "                  time_limit=time_limit,\n",
    "                  presets=['high_quality'])\n",
    "    \n",
    "    y_pred = predictor.predict(test_data)\n",
    "    \n",
    "    print(y_pred)\n",
    "    preds = pd.DataFrame()\n",
    "    preds['date_forecast'] = x_test['date_forecast']\n",
    "    preds['predicted'] = np.asarray(y_pred)\n",
    "    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(4))\n",
    "    preds.to_csv(str(limit) + random_string + '_' + location + '.csv')\n",
    "    print('Done with Location: ' + location + \"================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc6dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 34085\n",
      "Data points to be removed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/ut.py:128: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  preprocessed_df = preprocessed_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/ut.py:137: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_152751/\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_152751/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318752.49 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    34085\n",
      "Train Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 630.59471, 1165.90242)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1395167.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.64 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 38 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 36 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 38 | ['elevation:m', 'hour_0', 'hour_1', 'hour_10', 'hour_11', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.5s = Fit runtime\n",
      "\t81 features in original data used to generate 85 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1199.35s of the 1799.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-152.416\t = Validation score   (-mean_absolute_error)\n",
      "\t907.52s\t = Training   runtime\n",
      "\t126.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 275.33s of the 875.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-159.6631\t = Validation score   (-mean_absolute_error)\n",
      "\t228.98s\t = Training   runtime\n",
      "\t47.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 30.01s of the 630.13s of remaining time.\n",
      "\t-178.9161\t = Validation score   (-mean_absolute_error)\n",
      "\t195.78s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 432.82s of remaining time.\n",
      "\t-150.9636\t = Validation score   (-mean_absolute_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 432.56s of the 432.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-154.4415\t = Validation score   (-mean_absolute_error)\n",
      "\t55.71s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 367.51s of the 367.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-150.9592\t = Validation score   (-mean_absolute_error)\n",
      "\t34.23s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 323.77s of the 323.76s of remaining time.\n",
      "\t-149.0454\t = Validation score   (-mean_absolute_error)\n",
      "\t212.63s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 109.77s of the 109.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-150.5296\t = Validation score   (-mean_absolute_error)\n",
      "\t51.08s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 44.27s of the 44.26s of remaining time.\n",
      "\t-148.7243\t = Validation score   (-mean_absolute_error)\n",
      "\t40.61s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1.79s of the 1.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "2023-11-07 16:58:43,008\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=3018310, ip=10.1.4.6)\n",
      "  File \"/cluster/home/hansal/.local/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/cluster/home/hansal/.local/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/cluster/home/hansal/.local/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 300, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 16:58:43,008\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=3018304, ip=10.1.4.6)\n",
      "  File \"/cluster/home/hansal/.local/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/cluster/home/hansal/.local/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/cluster/home/hansal/.local/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 300, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -51.8s of remaining time.\n",
      "2023-11-07 16:58:43,172\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-07 16:58:43,470\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-07 16:58:43,476\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-07 16:58:43,482\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-07 16:58:43,486\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-148.1663\t = Validation score   (-mean_absolute_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1852.2s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t446.2s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t115.09s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t195.78s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.22s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t17.2s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t8.51s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t212.63s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "TBB Warning: The number of workers is currently limited to 0. The request for 47 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "\t3.01s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t40.61s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.3s\t = Training   runtime\n",
      "Refit complete, total runtime = 593.29s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_152751/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.581079\n",
      "1         0.667474\n",
      "2         0.496425\n",
      "3        54.344730\n",
      "4       241.898193\n",
      "           ...    \n",
      "1531    240.515976\n",
      "1532    106.801422\n",
      "1533      5.232025\n",
      "1534      0.924691\n",
      "1535      0.474150\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/ut.py:128: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  preprocessed_df = preprocessed_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/ut.py:137: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_160839/\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_160839/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318620.06 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    28595\n",
      "Train Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 97.15, 204.71614)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1395287.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 32844\n",
      "Data points to be removed: 4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 38 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 45 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 36 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 38 | ['elevation:m', 'hour_0', 'hour_1', 'hour_10', 'hour_11', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.6s = Fit runtime\n",
      "\t82 features in original data used to generate 86 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.15 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.63s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1199.28s of the 1799.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.3576\t = Validation score   (-mean_absolute_error)\n",
      "\t837.85s\t = Training   runtime\n",
      "\t103.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 341.0s of the 941.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.0928\t = Validation score   (-mean_absolute_error)\n",
      "\t284.31s\t = Training   runtime\n",
      "\t55.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 36.84s of the 636.93s of remaining time.\n",
      "\t-24.1645\t = Validation score   (-mean_absolute_error)\n",
      "\t162.16s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 473.64s of remaining time.\n",
      "\t-20.0282\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 473.41s of the 473.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.6084\t = Validation score   (-mean_absolute_error)\n",
      "\t52.02s\t = Training   runtime\n",
      "\t1.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 408.71s of the 408.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.1594\t = Validation score   (-mean_absolute_error)\n",
      "\t32.49s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 363.25s of the 363.24s of remaining time.\n",
      "\t-19.8141\t = Validation score   (-mean_absolute_error)\n",
      "\t187.51s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 174.76s of the 174.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.1111\t = Validation score   (-mean_absolute_error)\n",
      "\t49.21s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 113.08s of the 113.08s of remaining time.\n",
      "\t-19.6135\t = Validation score   (-mean_absolute_error)\n",
      "\t34.39s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 77.76s of the 77.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.1471\t = Validation score   (-mean_absolute_error)\n",
      "\t73.16s\t = Training   runtime\n",
      "\t3.44s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -8.12s of remaining time.\n",
      "\t-19.5846\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1808.49s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t440.49s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t146.5s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t162.16s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t16.71s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t7.71s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t187.51s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t3.23s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t34.39s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 4.\n",
      "\t16.63s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.33s\t = Training   runtime\n",
      "Refit complete, total runtime = 635.35s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_160839/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.030325\n",
      "1        0.030983\n",
      "2        0.027587\n",
      "3        5.417514\n",
      "4       60.632553\n",
      "          ...    \n",
      "1531    57.589378\n",
      "1532    16.108244\n",
      "1533     3.531607\n",
      "1534     0.107559\n",
      "1535     0.191787\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/ut.py:128: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  preprocessed_df = preprocessed_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/ut.py:137: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_164926/\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_164926/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318612.09 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    23985\n",
      "Train Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 84.38922, 171.29106)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1403422.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.37 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 26095\n",
      "Data points to be removed: 2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 38 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 36 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 38 | ['elevation:m', 'hour_0', 'hour_1', 'hour_10', 'hour_11', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.5s = Fit runtime\n",
      "\t81 features in original data used to generate 85 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.9 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1199.33s of the 1799.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "time_limit = 30 * 60\n",
    "do_prediction('A',time_limit)\n",
    "do_prediction('B',time_limit)\n",
    "do_prediction('C',time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeba554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

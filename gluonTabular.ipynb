{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b268a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import ut\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf07bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prediction(location, time_limit):\n",
    "    x_train, x_test = ut.preprocess_category(location)\n",
    "    x_train.drop([\"time\"], axis=1, inplace=True)\n",
    "\n",
    "    x_train['date_forecast'] = pd.to_datetime(x_train['date_forecast'])\n",
    "\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    label = 'pv_measurement'\n",
    "    train_data = TabularDataset(x_train)\n",
    "    \n",
    "    test_data = TabularDataset(x_test)\n",
    "    \n",
    "\n",
    "    predictor = TabularPredictor(label=label,\n",
    "                                 path=\"AutoGluonTesting\",\n",
    "                                 eval_metric='mean_absolute_error')\n",
    "\n",
    "    predictor.fit(train_data,\n",
    "                  time_limit=time_limit,\n",
    "                  presets=['high_quality'])\n",
    "    \n",
    "    y_pred = predictor.predict(test_data)\n",
    "    \n",
    "    print(y_pred)\n",
    "    preds = pd.DataFrame()\n",
    "    preds['date_forecast'] = x_test['date_forecast']\n",
    "    preds['predicted'] = np.asarray(y_pred)\n",
    "    random_string = ''.join(random.choice(string.ascii_letters) for _ in range(4))\n",
    "    preds.to_csv(location + str(time_limit) + random_string + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc6dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 34085\n",
      "Data points to be removed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/ut.py:128: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  preprocessed_df = preprocessed_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/ut.py:137: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_152751/\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 1800s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_152751/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318752.49 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    34085\n",
      "Train Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 630.59471, 1165.90242)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1395167.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.64 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 38 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 36 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 38 | ['elevation:m', 'hour_0', 'hour_1', 'hour_10', 'hour_11', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.5s = Fit runtime\n",
      "\t81 features in original data used to generate 85 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1199.35s of the 1799.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-152.416\t = Validation score   (-mean_absolute_error)\n",
      "\t907.52s\t = Training   runtime\n",
      "\t126.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 275.33s of the 875.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-159.6631\t = Validation score   (-mean_absolute_error)\n",
      "\t228.98s\t = Training   runtime\n",
      "\t47.37s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 30.01s of the 630.13s of remaining time.\n",
      "\t-178.9161\t = Validation score   (-mean_absolute_error)\n",
      "\t195.78s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 432.82s of remaining time.\n",
      "\t-150.9636\t = Validation score   (-mean_absolute_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 432.56s of the 432.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-154.4415\t = Validation score   (-mean_absolute_error)\n",
      "\t55.71s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 367.51s of the 367.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-150.9592\t = Validation score   (-mean_absolute_error)\n",
      "\t34.23s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 323.77s of the 323.76s of remaining time.\n"
     ]
    }
   ],
   "source": [
    "time_limit = 30 * 60\n",
    "do_prediction('A',time_limit)\n",
    "do_prediction('B',time_limit)\n",
    "do_prediction('C',time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeba554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

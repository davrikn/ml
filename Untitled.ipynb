{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a4fddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 34085\n",
      "Data points to be removed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/utils.py:136: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_df = estimated_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/utils.py:145: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutoGluonTesting\"\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutoGluonTesting/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318518.22 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    29667\n",
      "Train Data Columns: 82\n",
      "Tuning Data Rows:    1325\n",
      "Tuning Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 674.14552, 1195.53172)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    779157.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.8 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 37 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 31 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('object', [])   :  5 | ['month_5', 'month_6', 'month_7', 'month_8', 'month_9']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 37 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t1.3s = Fit runtime\n",
      "\t80 features in original data used to generate 84 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.59 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3598.54s of the 3598.52s of remaining time.\n",
      "\t-122.4731\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3598.08s of the 3598.06s of remaining time.\n",
      "\t-122.4731\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3597.57s of the 3597.55s of remaining time.\n",
      "\t-73.1599\t = Validation score   (-mean_absolute_error)\n",
      "\t13.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3583.39s of the 3583.37s of remaining time.\n",
      "\t-76.9205\t = Validation score   (-mean_absolute_error)\n",
      "\t15.18s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3567.88s of the 3567.87s of remaining time.\n",
      "\t-79.7937\t = Validation score   (-mean_absolute_error)\n",
      "\t196.45s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3370.68s of the 3370.66s of remaining time.\n",
      "\t-81.3243\t = Validation score   (-mean_absolute_error)\n",
      "\t6.4s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3364.2s of the 3364.19s of remaining time.\n",
      "\t-70.0395\t = Validation score   (-mean_absolute_error)\n",
      "\t52.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3310.71s of the 3310.7s of remaining time.\n",
      "\t-78.0503\t = Validation score   (-mean_absolute_error)\n",
      "\t999.33s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 2309.96s of the 2309.94s of remaining time.\n",
      "\t-71.6256\t = Validation score   (-mean_absolute_error)\n",
      "\t13.33s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 2296.52s of the 2296.51s of remaining time.\n",
      "\t-61.2818\t = Validation score   (-mean_absolute_error)\n",
      "\t1408.44s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 887.1s of the 887.09s of remaining time.\n",
      "\t-71.8808\t = Validation score   (-mean_absolute_error)\n",
      "\t79.21s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 807.07s of remaining time.\n",
      "\t-61.2818\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2793.55s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonTesting/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5.637497e-07\n",
      "1       5.549605e-08\n",
      "2       9.555703e-08\n",
      "3       5.960649e+01\n",
      "4       4.639298e+02\n",
      "            ...     \n",
      "1531    2.019077e+02\n",
      "1532    6.930254e+01\n",
      "1533    1.879984e+00\n",
      "1534    5.976955e-04\n",
      "1535    1.166884e-06\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n",
      "Done with Location: A================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/utils.py:136: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_df = estimated_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/utils.py:145: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutoGluonTesting\"\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutoGluonTesting/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318465.54 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    24970\n",
      "Train Data Columns: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 32844\n",
      "Data points to be removed: 4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning Data Rows:    1087\n",
      "Tuning Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 103.9337, 211.75438)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    762080.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.92 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 37 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 31 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('object', [])   :  5 | ['month_5', 'month_6', 'month_7', 'month_8', 'month_9']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 37 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.8s = Fit runtime\n",
      "\t81 features in original data used to generate 85 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.92s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.08s of the 3599.07s of remaining time.\n",
      "\t-7.555\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t8.98s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3589.87s of the 3589.87s of remaining time.\n",
      "\t-7.555\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t8.67s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3580.95s of the 3580.95s of remaining time.\n",
      "\t-3.2688\t = Validation score   (-mean_absolute_error)\n",
      "\t15.98s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3564.43s of the 3564.43s of remaining time.\n",
      "\t-3.3033\t = Validation score   (-mean_absolute_error)\n",
      "\t17.93s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3546.18s of the 3546.17s of remaining time.\n",
      "\t-2.8099\t = Validation score   (-mean_absolute_error)\n",
      "\t182.97s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3362.59s of the 3362.59s of remaining time.\n",
      "\t-4.4283\t = Validation score   (-mean_absolute_error)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3358.9s of the 3358.89s of remaining time.\n",
      "\t-2.6035\t = Validation score   (-mean_absolute_error)\n",
      "\t43.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3315.28s of the 3315.27s of remaining time.\n",
      "\t-6.0859\t = Validation score   (-mean_absolute_error)\n",
      "\t1012.41s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 2301.09s of the 2301.09s of remaining time.\n",
      "\t-3.004\t = Validation score   (-mean_absolute_error)\n",
      "\t15.7s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 2285.14s of the 2285.13s of remaining time.\n",
      "\t-2.9954\t = Validation score   (-mean_absolute_error)\n",
      "\t1379.51s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 904.61s of the 904.61s of remaining time.\n",
      "\t-3.1823\t = Validation score   (-mean_absolute_error)\n",
      "\t88.54s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 815.16s of remaining time.\n",
      "\t-2.6035\t = Validation score   (-mean_absolute_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2785.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonTesting/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.000000\n",
      "1        0.000000\n",
      "2        0.000000\n",
      "3        7.549750\n",
      "4       51.744251\n",
      "          ...    \n",
      "1531    42.665001\n",
      "1532    12.149750\n",
      "1533     0.043125\n",
      "1534     0.000000\n",
      "1535     0.000000\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n",
      "Done with Location: B================================================================\n",
      "Total data points: 26095\n",
      "Data points to be removed: 2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/utils.py:136: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_df = estimated_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/utils.py:145: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutoGluonTesting\"\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutoGluonTesting/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318495.78 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    21032\n",
      "Train Data Columns: 82\n",
      "Tuning Data Rows:    885\n",
      "Tuning Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 90.45849, 177.65934)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    777426.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 37 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 31 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('object', [])   :  5 | ['month_5', 'month_6', 'month_7', 'month_8', 'month_9']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 37 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t1.0s = Fit runtime\n",
      "\t80 features in original data used to generate 84 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.37 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3598.82s of the 3598.82s of remaining time.\n",
      "\t-25.9595\t = Validation score   (-mean_absolute_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t6.75s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3591.75s of the 3591.75s of remaining time.\n",
      "\t-25.9525\t = Validation score   (-mean_absolute_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t7.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3584.31s of the 3584.3s of remaining time.\n",
      "\t-4.8766\t = Validation score   (-mean_absolute_error)\n",
      "\t16.46s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3567.46s of the 3567.46s of remaining time.\n",
      "\t-5.0945\t = Validation score   (-mean_absolute_error)\n",
      "\t21.88s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3545.16s of the 3545.16s of remaining time.\n",
      "\t-5.1721\t = Validation score   (-mean_absolute_error)\n",
      "\t140.05s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3404.68s of the 3404.67s of remaining time.\n",
      "\t-5.3566\t = Validation score   (-mean_absolute_error)\n",
      "\t4.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3400.24s of the 3400.23s of remaining time.\n",
      "\t-5.0983\t = Validation score   (-mean_absolute_error)\n",
      "\t28.57s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3370.82s of the 3370.81s of remaining time.\n",
      "\t-7.1336\t = Validation score   (-mean_absolute_error)\n",
      "\t786.63s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 2583.23s of the 2583.22s of remaining time.\n",
      "\t-5.0419\t = Validation score   (-mean_absolute_error)\n",
      "\t13.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 2569.98s of the 2569.97s of remaining time.\n",
      "\t-4.6631\t = Validation score   (-mean_absolute_error)\n",
      "\t560.41s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 2008.48s of the 2008.47s of remaining time.\n",
      "\t-5.1542\t = Validation score   (-mean_absolute_error)\n",
      "\t91.87s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1915.85s of remaining time.\n",
      "\t-4.6223\t = Validation score   (-mean_absolute_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1684.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonTesting/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.113029\n",
      "1        0.113029\n",
      "2        0.113026\n",
      "3        0.897340\n",
      "4       29.660862\n",
      "          ...    \n",
      "1531    35.648224\n",
      "1532    11.285740\n",
      "1533     0.557676\n",
      "1534     0.071689\n",
      "1535     0.099831\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n",
      "Done with Location: C================================================================\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import utils\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from autogluon.common import space\n",
    "\n",
    "\n",
    "def do_prediction(location, limit, name):\n",
    "    x_train, tuning_data, x_test = utils.preprocess_category_estimated_observed(location)\n",
    "    x_train.drop([\"time\"], axis=1, inplace=True)\n",
    "    tuning_data.drop([\"time\"], axis=1, inplace=True)\n",
    "\n",
    "    x_train['date_forecast'] = pd.to_datetime(x_train['date_forecast'])\n",
    "    tuning_data['date_forecast'] = pd.to_datetime(tuning_data['date_forecast'])\n",
    "\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    label = 'pv_measurement'\n",
    "    train_data = TabularDataset(x_train)\n",
    "\n",
    "    tuning_data = TabularDataset(tuning_data)\n",
    "    thirty_percent_index = int(len(tuning_data) * 0.3)\n",
    "    tuning_data = tuning_data.iloc[:thirty_percent_index]\n",
    "\n",
    "    test_data = TabularDataset(x_test)\n",
    "\n",
    "    predictor = TabularPredictor(label=label,\n",
    "                                 path=\"AutoGluonTesting\",\n",
    "                                 eval_metric='mean_absolute_error')\n",
    "    \n",
    "    predictor.fit(train_data,\n",
    "                  time_limit=limit,\n",
    "                  tuning_data=tuning_data)\n",
    "\n",
    "    y_pred = predictor.predict(test_data)\n",
    "\n",
    "    print(y_pred)\n",
    "    preds = pd.DataFrame()\n",
    "    preds['date_forecast'] = x_test['date_forecast']\n",
    "    preds['predicted'] = np.asarray(y_pred)\n",
    "    preds.to_csv(str(limit) + name + '_' + location + '.csv')\n",
    "\n",
    "time_limit = 60 * 60\n",
    "name=\"testing_small_train_tuning\"\n",
    "do_prediction('A', time_limit, name)\n",
    "do_prediction('B', time_limit, name)\n",
    "do_prediction('C', time_limit, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c2471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

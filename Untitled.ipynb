{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dffa8e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 34085\n",
      "Data points to be removed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/utils.py:136: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_df = estimated_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/utils.py:145: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "Beginning AutoGluon training ... Time limit = 2700s\n",
      "AutoGluon will save models to \"AutoGluonTesting/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318607.94 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    29667\n",
      "Train Data Columns: 82\n",
      "Tuning Data Rows:    1767\n",
      "Tuning Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 674.14552, 1195.53172)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    766879.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.97 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 37 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 31 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('object', [])   :  5 | ['month_5', 'month_6', 'month_7', 'month_8', 'month_9']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 37 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t1.5s = Fit runtime\n",
      "\t80 features in original data used to generate 84 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.7 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.61s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 2698.39s of the 2698.38s of remaining time.\n",
      "\t-97.4863\t = Validation score   (-mean_absolute_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 2696.77s of the 2696.76s of remaining time.\n",
      "\t-97.4863\t = Validation score   (-mean_absolute_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 2696.0s of the 2696.0s of remaining time.\n",
      "\t-59.4784\t = Validation score   (-mean_absolute_error)\n",
      "\t15.6s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 2680.1s of the 2680.1s of remaining time.\n",
      "\t-63.3832\t = Validation score   (-mean_absolute_error)\n",
      "\t14.62s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 2665.2s of the 2665.19s of remaining time.\n",
      "\t-66.9859\t = Validation score   (-mean_absolute_error)\n",
      "\t211.71s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 2452.45s of the 2452.44s of remaining time.\n",
      "TBB Warning: The number of workers is currently limited to 0. The request for 39 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.\n",
      "\n",
      "\t-68.1586\t = Validation score   (-mean_absolute_error)\n",
      "\t8.75s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 2443.6s of the 2443.59s of remaining time.\n",
      "\t-56.6609\t = Validation score   (-mean_absolute_error)\n",
      "\t55.12s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 2387.5s of the 2387.49s of remaining time.\n",
      "\t-66.7662\t = Validation score   (-mean_absolute_error)\n",
      "\t1119.68s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 1266.24s of the 1266.23s of remaining time.\n",
      "\t-59.279\t = Validation score   (-mean_absolute_error)\n",
      "\t11.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 1254.91s of the 1254.91s of remaining time.\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 46)\n",
      "\t-50.407\t = Validation score   (-mean_absolute_error)\n",
      "\t1246.26s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 7.87s of the 7.86s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 24. Best iteration is:\n",
      "\t[24]\tvalid_set's l1: 341.344\n",
      "\t-341.3435\t = Validation score   (-mean_absolute_error)\n",
      "\t8.1s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the -0.54s of remaining time.\n",
      "\t-50.385\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2701.09s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonTesting/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5.521260e-07\n",
      "1       5.435180e-08\n",
      "2       1.303377e-02\n",
      "3       6.025037e+01\n",
      "4       4.628395e+02\n",
      "            ...     \n",
      "1531    2.030170e+02\n",
      "1532    6.977433e+01\n",
      "1533    1.900524e+00\n",
      "1534    1.023860e-03\n",
      "1535    3.138337e-05\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n",
      "Done with Location: A================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/utils.py:136: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_df = estimated_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/utils.py:145: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutoGluonTesting\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 32844\n",
      "Data points to be removed: 4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 2700s\n",
      "AutoGluon will save models to \"AutoGluonTesting/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318561.75 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    24970\n",
      "Train Data Columns: 82\n",
      "Tuning Data Rows:    1450\n",
      "Tuning Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 103.9337, 211.75438)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    765704.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 37 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 31 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('object', [])   :  5 | ['month_5', 'month_6', 'month_7', 'month_8', 'month_9']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 37 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t0.9s = Fit runtime\n",
      "\t81 features in original data used to generate 85 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 2698.96s of the 2698.95s of remaining time.\n",
      "\t-6.6579\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t11.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 2687.78s of the 2687.77s of remaining time.\n",
      "\t-6.6579\t = Validation score   (-mean_absolute_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t11.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 2676.54s of the 2676.53s of remaining time.\n",
      "\t-3.2258\t = Validation score   (-mean_absolute_error)\n",
      "\t13.54s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 2662.78s of the 2662.77s of remaining time.\n",
      "\t-3.2288\t = Validation score   (-mean_absolute_error)\n",
      "\t16.11s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 2646.42s of the 2646.41s of remaining time.\n",
      "\t-2.8448\t = Validation score   (-mean_absolute_error)\n",
      "\t182.21s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 2463.43s of the 2463.42s of remaining time.\n",
      "\t-4.4001\t = Validation score   (-mean_absolute_error)\n",
      "\t3.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 2459.95s of the 2459.94s of remaining time.\n",
      "\t-2.7065\t = Validation score   (-mean_absolute_error)\n",
      "\t43.75s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 2415.52s of the 2415.51s of remaining time.\n",
      "\t-6.5549\t = Validation score   (-mean_absolute_error)\n",
      "\t797.61s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 1616.98s of the 1616.97s of remaining time.\n",
      "\t-3.0515\t = Validation score   (-mean_absolute_error)\n",
      "\t11.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 1605.52s of the 1605.51s of remaining time.\n",
      "\t-3.2137\t = Validation score   (-mean_absolute_error)\n",
      "\t443.1s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1161.22s of the 1161.21s of remaining time.\n",
      "\t-3.2032\t = Validation score   (-mean_absolute_error)\n",
      "\t74.2s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1086.36s of remaining time.\n",
      "\t-2.7065\t = Validation score   (-mean_absolute_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1614.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonTesting/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.000000\n",
      "1        0.000000\n",
      "2        0.000000\n",
      "3        7.549750\n",
      "4       51.744251\n",
      "          ...    \n",
      "1531    42.665001\n",
      "1532    12.149750\n",
      "1533     0.043125\n",
      "1534     0.000000\n",
      "1535     0.000000\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n",
      "Done with Location: B================================================================\n",
      "Total data points: 26095\n",
      "Data points to be removed: 2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/hansal/ml/utils.py:136: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_df = estimated_df.resample('H').mean()\n",
      "/cluster/home/hansal/ml/utils.py:145: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  test_df = test_df.resample('H').mean()\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutoGluonTesting\"\n",
      "Beginning AutoGluon training ... Time limit = 2700s\n",
      "AutoGluon will save models to \"AutoGluonTesting/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Nov 9 20:13:27 UTC 2022\n",
      "Disk Space Avail:   318576.66 GB / 618408.77 GB (51.5%)\n",
      "Train Data Rows:    21032\n",
      "Train Data Columns: 82\n",
      "Tuning Data Rows:    1181\n",
      "Tuning Data Columns: 82\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 90.45849, 177.65934)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    785742.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 37 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  1 | ['date_forecast']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      : 31 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('object', [])   :  5 | ['month_5', 'month_6', 'month_7', 'month_8', 'month_9']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 42 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool'])            : 37 | ['hour_0', 'hour_1', 'hour_10', 'hour_11', 'hour_12', ...]\n",
      "\t\t('int', ['datetime_as_int']) :  5 | ['date_forecast', 'date_forecast.year', 'date_forecast.month', 'date_forecast.day', 'date_forecast.dayofweek']\n",
      "\t1.0s = Fit runtime\n",
      "\t80 features in original data used to generate 84 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.44 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 2698.83s of the 2698.82s of remaining time.\n",
      "\t-25.9372\t = Validation score   (-mean_absolute_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t7.53s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 2691.13s of the 2691.12s of remaining time.\n",
      "\t-25.9301\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t7.49s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 2683.47s of the 2683.46s of remaining time.\n",
      "\t-4.2204\t = Validation score   (-mean_absolute_error)\n",
      "\t13.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 2670.01s of the 2670.0s of remaining time.\n",
      "\t-4.355\t = Validation score   (-mean_absolute_error)\n",
      "\t17.31s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 2652.45s of the 2652.44s of remaining time.\n",
      "\t-4.3029\t = Validation score   (-mean_absolute_error)\n",
      "\t105.39s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 2546.7s of the 2546.69s of remaining time.\n",
      "\t-4.765\t = Validation score   (-mean_absolute_error)\n",
      "\t5.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 2540.75s of the 2540.74s of remaining time.\n",
      "\t-4.1839\t = Validation score   (-mean_absolute_error)\n",
      "\t25.81s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 2514.53s of the 2514.52s of remaining time.\n",
      "\t-6.3281\t = Validation score   (-mean_absolute_error)\n",
      "\t598.15s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 1915.26s of the 1915.25s of remaining time.\n",
      "\t-4.1908\t = Validation score   (-mean_absolute_error)\n",
      "\t11.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 1903.54s of the 1903.53s of remaining time.\n",
      "\t-3.8686\t = Validation score   (-mean_absolute_error)\n",
      "\t395.4s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 1507.42s of the 1507.41s of remaining time.\n",
      "\t-4.3776\t = Validation score   (-mean_absolute_error)\n",
      "\t78.92s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1427.79s of remaining time.\n",
      "\t-3.845\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1272.77s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonTesting/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.018382\n",
      "1        0.018382\n",
      "2        0.018377\n",
      "3        1.596262\n",
      "4       31.714375\n",
      "          ...    \n",
      "1531    36.085350\n",
      "1532    11.440482\n",
      "1533     0.330282\n",
      "1534     0.008997\n",
      "1535     0.013742\n",
      "Name: pv_measurement, Length: 1536, dtype: float32\n",
      "Done with Location: C================================================================\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import utils\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "def do_prediction(location, limit):\n",
    "    x_train, tuning_data, x_test = utils.preprocess_category_estimated_observed(location)\n",
    "    x_train.drop([\"time\"], axis=1, inplace=True)\n",
    "    tuning_data.drop([\"time\"], axis=1, inplace=True)\n",
    "\n",
    "    x_train['date_forecast'] = pd.to_datetime(x_train['date_forecast'])\n",
    "    tuning_data['date_forecast'] = pd.to_datetime(tuning_data['date_forecast'])\n",
    "\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    label = 'pv_measurement'\n",
    "    train_data = TabularDataset(x_train)\n",
    "\n",
    "    tuning_data = TabularDataset(tuning_data)\n",
    "    thirty_percent_index = int(len(tuning_data) * 0.4)\n",
    "    tuning_data = tuning_data.iloc[:thirty_percent_index]\n",
    "\n",
    "    test_data = TabularDataset(x_test)\n",
    "\n",
    "    predictor = TabularPredictor(label=label,\n",
    "                                 path=\"AutoGluonTesting\",\n",
    "                                 eval_metric='mean_absolute_error')\n",
    "\n",
    "    predictor.fit(train_data,\n",
    "                  time_limit=limit,\n",
    "                  tuning_data=tuning_data, )\n",
    "\n",
    "    y_pred = predictor.predict(test_data)\n",
    "\n",
    "    print(y_pred)\n",
    "    preds = pd.DataFrame()\n",
    "    preds['date_forecast'] = x_test['date_forecast']\n",
    "    preds['predicted'] = np.asarray(y_pred)\n",
    "    random_string = ''.join(random.choices(string.ascii_uppercase, k=4))\n",
    "    preds.to_csv(str(limit) + random_string + '_' + location + '.csv')\n",
    "    print('Done with Location: ' + location + \"================================================================\")\n",
    "\n",
    "\n",
    "def do_prediction_no_tuning(location, limit):\n",
    "    x_train, x_test = utils.preprocess_category(location)\n",
    "    x_train.drop([\"time\"], axis=1, inplace=True)\n",
    "\n",
    "    x_train['date_forecast'] = pd.to_datetime(x_train['date_forecast'])\n",
    "\n",
    "    x_test.fillna(0, inplace=True)\n",
    "\n",
    "    label = 'pv_measurement'\n",
    "    train_data = TabularDataset(x_train)\n",
    "\n",
    "    test_data = TabularDataset(x_test)\n",
    "\n",
    "    predictor = TabularPredictor(label=label,\n",
    "                                 path=\"AutoGluonTesting\",\n",
    "                                 eval_metric='mean_absolute_error')\n",
    "\n",
    "    predictor.fit(train_data,\n",
    "                  time_limit=time_limit,\n",
    "                  presets=['high_quality'])\n",
    "\n",
    "    y_pred = predictor.predict(test_data)\n",
    "\n",
    "    print(y_pred)\n",
    "    preds = pd.DataFrame()\n",
    "    preds['date_forecast'] = x_test['date_forecast']\n",
    "    preds['predicted'] = np.asarray(y_pred)\n",
    "    random_string = ''.join(random.choices(string.ascii_uppercase, k=4))\n",
    "    preds.to_csv(str(limit) + random_string + '_' + location + '.csv')\n",
    "    print('Done with Location: ' + location + \"================================================================\")\n",
    "\n",
    "\n",
    "time_limit = 45 * 60\n",
    "do_prediction('A', time_limit)\n",
    "do_prediction('B', time_limit)\n",
    "do_prediction('C', time_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f733ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
